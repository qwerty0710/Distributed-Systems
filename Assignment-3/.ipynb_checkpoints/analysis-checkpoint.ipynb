{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_url = \"http://localhost:5000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-1. Default configuration with 6 servers, 4 shards, 3 replicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T13:23:42.290782Z",
     "start_time": "2024-03-27T13:23:42.279499Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 22\u001B[0m\n\u001B[1;32m      1\u001B[0m payload \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mN\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m6\u001B[39m,\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mschema\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     20\u001B[0m     },\n\u001B[1;32m     21\u001B[0m }\n\u001B[0;32m---> 22\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mrequests\u001B[49m\u001B[38;5;241m.\u001B[39mpost(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdocker_url\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/init\u001B[39m\u001B[38;5;124m\"\u001B[39m, json\u001B[38;5;241m=\u001B[39mpayload)\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28mprint\u001B[39m(res\u001B[38;5;241m.\u001B[39mjson())\n",
      "\u001B[0;31mNameError\u001B[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"N\": 6,\n",
    "    \"schema\": {\n",
    "        \"columns\": [\"Stud_id\", \"Stud_name\", \"Stud_marks\"],\n",
    "        \"dtypes\": [\"Number\", \"String\", \"Number\"],\n",
    "    },\n",
    "    \"shards\": [\n",
    "        {\"Stud_id_low\": 0, \"Shard_id\": \"sh1\", \"Shard_size\": 4096},\n",
    "        {\"Stud_id_low\": 4096, \"Shard_id\": \"sh2\", \"Shard_size\": 4096},\n",
    "        {\"Stud_id_low\": 8192, \"Shard_id\": \"sh3\", \"Shard_size\": 4096},\n",
    "        {\"Stud_id_low\": 12288, \"Shard_id\": \"sh4\", \"Shard_size\": 4096},\n",
    "    ],\n",
    "    \"servers\": {\n",
    "        \"Server0\": [\"sh1\", \"sh2\"],\n",
    "        \"Server1\": [\"sh3\", \"sh4\"],\n",
    "        \"Server2\": [\"sh1\", \"sh3\"],\n",
    "        \"Server3\": [\"sh4\", \"sh2\"],\n",
    "        \"Server4\": [\"sh1\", \"sh4\"],\n",
    "        \"Server5\": [\"sh3\", \"sh2\"],\n",
    "    },\n",
    "}\n",
    "res = requests.post(f\"{docker_url}/init\", json=payload)\n",
    "print(res.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T13:23:36.653910Z",
     "start_time": "2024-03-27T13:23:36.637454Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 22\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m200\u001B[39m:\n\u001B[1;32m     20\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mres\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m in write\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 22\u001B[0m total_start_time\u001B[38;5;241m=\u001B[39m\u001B[43mtime\u001B[49m\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m concurrent\u001B[38;5;241m.\u001B[39mfutures\u001B[38;5;241m.\u001B[39mThreadPoolExecutor(max_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m executor:\n\u001B[1;32m     24\u001B[0m     write_tasks\u001B[38;5;241m=\u001B[39m[executor\u001B[38;5;241m.\u001B[39msubmit(make_write_request) \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_requests)]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "num_requests = 10000\n",
    "\n",
    "write_times= []\n",
    "max_stud_id = 16383\n",
    "\n",
    "def make_write_request():\n",
    "    payload = {\n",
    "        \"data\": [\n",
    "            {\n",
    "                \"Stud_id\": random.randint(0, max_stud_id),\n",
    "                \"Stud_name\": \"GHI\",\n",
    "                \"Stud_marks\": random.randint(0, 100),\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "    start_time = time.time()\n",
    "    res = requests.post(f\"{docker_url}/write\", json=payload)\n",
    "    write_times.append(time.time() - start_time)\n",
    "    if res.status_code != 200:\n",
    "        print(f\"Error {res.status_code} in write\")\n",
    "\n",
    "total_start_time=time.time()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    write_tasks=[executor.submit(make_write_request) for _ in range(num_requests)]\n",
    "    concurrent.futures.wait(write_tasks)\n",
    "\n",
    "print(f\"Total time taken: {time.time() - total_start_time} secs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(write_times, 100, (0,4))\n",
    "plt.xlabel(\"Time taken for write (sec)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"A1: Time distribution for write execution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_requests = 10000\n",
    "\n",
    "read_times = []\n",
    "max_stud_id = 16383\n",
    "\n",
    "\n",
    "def make_read_request():\n",
    "    low = random.randint(0, max_stud_id)\n",
    "    payload = {\"Stud_id\": {\"low\": low, \"high\": low + 50}}\n",
    "    start_time = time.time()\n",
    "    res = requests.get(f\"{docker_url}/read\", json=payload)\n",
    "    read_times.append(time.time() - start_time)\n",
    "    if res.status_code != 200:\n",
    "        print(f\"Error {res.status_code} in read\")\n",
    "\n",
    "total_start_time=time.time()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    read_tasks=[executor.submit(make_read_request) for _ in range(num_requests)]\n",
    "    concurrent.futures.wait(read_tasks)\n",
    "\n",
    "print(f\"Total time taken: {time.time() - total_start_time} secs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(read_times, 100, (0,1))\n",
    "plt.xlabel(\"Time taken for read (sec)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"A1: Time distribution for read execution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"n\": 6,\n",
    "    \"servers\": [\"Server0\", \"Server1\", \"Server2\", \"Server3\", \"Server4\", \"Server5\"],\n",
    "}\n",
    "res = requests.delete(f\"{docker_url}/rm\", json=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-2. 6 servers, 4 shards, 6 replicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"N\": 6,\n",
    "    \"schema\": {\n",
    "        \"columns\": [\"Stud_id\", \"Stud_name\", \"Stud_marks\"],\n",
    "        \"dtypes\": [\"Number\", \"String\", \"Number\"],\n",
    "    },\n",
    "    \"shards\": [\n",
    "        {\"Stud_id_low\": 0, \"Shard_id\": \"sh1\", \"Shard_size\": 4096},\n",
    "        {\"Stud_id_low\": 4096, \"Shard_id\": \"sh2\", \"Shard_size\": 4096},\n",
    "        {\"Stud_id_low\": 8192, \"Shard_id\": \"sh3\", \"Shard_size\": 4096},\n",
    "        {\"Stud_id_low\": 12288, \"Shard_id\": \"sh4\", \"Shard_size\": 4096},\n",
    "    ],\n",
    "    \"servers\": {\n",
    "        \"Server0\": [\"sh1\", \"sh2\", \"sh3\", \"sh4\"],\n",
    "        \"Server1\": [\"sh1\", \"sh2\", \"sh3\", \"sh4\"],\n",
    "        \"Server2\": [\"sh1\", \"sh2\", \"sh3\", \"sh4\"],\n",
    "        \"Server3\": [\"sh1\", \"sh2\", \"sh3\", \"sh4\"],\n",
    "        \"Server4\": [\"sh1\", \"sh2\", \"sh3\", \"sh4\"],\n",
    "        \"Server5\": [\"sh1\", \"sh2\", \"sh3\", \"sh4\"],\n",
    "    },\n",
    "}\n",
    "res = requests.post(f\"{docker_url}/init\", json=payload)\n",
    "print(res.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_requests = 10000\n",
    "\n",
    "write_times= []\n",
    "max_stud_id = 16383\n",
    "\n",
    "def make_write_request():\n",
    "    payload = {\n",
    "        \"data\": [\n",
    "            {\n",
    "                \"Stud_id\": random.randint(0, max_stud_id),\n",
    "                \"Stud_name\": \"GHI\",\n",
    "                \"Stud_marks\": random.randint(0, 100),\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "    start_time = time.time()\n",
    "    res = requests.post(f\"{docker_url}/write\", json=payload)\n",
    "    write_times.append(time.time() - start_time)\n",
    "    if res.status_code != 200:\n",
    "        print(f\"Error {res.status_code} in write\")\n",
    "\n",
    "total_start_time=time.time()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    write_tasks=[executor.submit(make_write_request) for _ in range(num_requests)]\n",
    "    concurrent.futures.wait(write_tasks)\n",
    "\n",
    "print(f\"Total time taken: {time.time() - total_start_time} secs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(write_times, 100, (0,4))\n",
    "plt.xlabel(\"Time taken for write (sec)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"A2: Time distribution for write execution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_requests = 10000\n",
    "\n",
    "read_times = []\n",
    "max_stud_id = 16383\n",
    "\n",
    "\n",
    "def make_read_request():\n",
    "    low = random.randint(0, max_stud_id)\n",
    "    payload = {\"Stud_id\": {\"low\": low, \"high\": low + 50}}\n",
    "    start_time = time.time()\n",
    "    res = requests.get(f\"{docker_url}/read\", json=payload)\n",
    "    read_times.append(time.time() - start_time)\n",
    "    if res.status_code != 200:\n",
    "        print(f\"Error {res.status_code} in read\")\n",
    "\n",
    "total_start_time=time.time()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    read_tasks=[executor.submit(make_read_request) for _ in range(num_requests)]\n",
    "    concurrent.futures.wait(read_tasks)\n",
    "\n",
    "print(f\"Total time taken: {time.time() - total_start_time} secs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(read_times, 100, (0,1))\n",
    "plt.xlabel(\"Time taken for read (sec)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"A2: Time distribution for read execution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"n\": 6,\n",
    "    \"servers\": [\"Server0\", \"Server1\", \"Server2\", \"Server3\", \"Server4\", \"Server5\"],\n",
    "}\n",
    "res = requests.delete(f\"{docker_url}/rm\", json=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-3. 10 servers, 6 shards, 8 replicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"N\": 10,\n",
    "    \"schema\": {\n",
    "        \"columns\": [\"Stud_id\", \"Stud_name\", \"Stud_marks\"],\n",
    "        \"dtypes\": [\"Number\", \"String\", \"Number\"],\n",
    "    },\n",
    "    \"shards\": [\n",
    "        {\"Stud_id_low\": 0, \"Shard_id\": \"sh1\", \"Shard_size\": 4096},\n",
    "        {\"Stud_id_low\": 4096, \"Shard_id\": \"sh2\", \"Shard_size\": 4096},\n",
    "        {\"Stud_id_low\": 8192, \"Shard_id\": \"sh3\", \"Shard_size\": 4096},\n",
    "        {\"Stud_id_low\": 12288, \"Shard_id\": \"sh4\", \"Shard_size\": 4096},\n",
    "        {\"Stud_id_low\": 16384, \"Shard_id\": \"sh5\", \"Shard_size\": 4096},\n",
    "        {\"Stud_id_low\": 20480, \"Shard_id\": \"sh6\", \"Shard_size\": 4096},\n",
    "    ],\n",
    "    \"servers\": {\n",
    "        \"Server0\": [\"sh1\", \"sh2\", \"sh4\", \"sh6\"],\n",
    "        \"Server1\": [\"sh1\", \"sh2\", \"sh3\", \"sh4\", \"sh5\"],\n",
    "        \"Server2\": [\"sh1\", \"sh2\", \"sh3\", \"sh5\", \"sh6\"],\n",
    "        \"Server3\": [\"sh4\", \"sh2\", \"sh3\", \"sh5\", \"sh6\"],\n",
    "        \"Server4\": [\"sh1\", \"sh4\", \"sh5\", \"sh6\"],\n",
    "        \"Server5\": [\"sh3\", \"sh2\", \"sh5\", \"sh6\"],\n",
    "        \"Server6\": [\"sh1\", \"sh3\", \"sh4\", \"sh5\", \"sh6\"],\n",
    "        \"Server7\": [\"sh1\", \"sh3\", \"sh4\", \"sh2\", \"sh5\"],\n",
    "        \"Server8\": [\"sh1\", \"sh2\", \"sh3\", \"sh4\", \"sh6\"],\n",
    "        \"Server9\": [\"sh1\", \"sh2\", \"sh3\", \"sh4\", \"sh5\", \"sh6\"],\n",
    "    },\n",
    "}\n",
    "res = requests.post(f\"{docker_url}/init\", json=payload)\n",
    "print(res.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_requests = 10000\n",
    "\n",
    "write_times= []\n",
    "max_stud_id = 24575\n",
    "\n",
    "def make_write_request():\n",
    "    payload = {\n",
    "        \"data\": [\n",
    "            {\n",
    "                \"Stud_id\": random.randint(0, max_stud_id),\n",
    "                \"Stud_name\": \"GHI\",\n",
    "                \"Stud_marks\": random.randint(0, 100),\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "    start_time = time.time()\n",
    "    res = requests.post(f\"{docker_url}/write\", json=payload)\n",
    "    write_times.append(time.time() - start_time)\n",
    "    if res.status_code != 200:\n",
    "        print(f\"Error {res.status_code} in write\")\n",
    "\n",
    "total_start_time=time.time()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    write_tasks=[executor.submit(make_write_request) for _ in range(num_requests)]\n",
    "    concurrent.futures.wait(write_tasks)\n",
    "\n",
    "print(f\"Total time taken: {time.time() - total_start_time} secs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(write_times, 100, (0,4))\n",
    "plt.xlabel(\"Time taken for write (sec)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"A3: Time distribution for write execution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_requests = 10000\n",
    "\n",
    "read_times = []\n",
    "max_stud_id = 24575\n",
    "\n",
    "\n",
    "def make_read_request():\n",
    "    low = random.randint(0, max_stud_id)\n",
    "    payload = {\"Stud_id\": {\"low\": low, \"high\": low + 50}}\n",
    "    start_time = time.time()\n",
    "    res = requests.get(f\"{docker_url}/read\", json=payload)\n",
    "    read_times.append(time.time() - start_time)\n",
    "    if res.status_code != 200:\n",
    "        print(f\"Error {res.status_code} in read\")\n",
    "\n",
    "total_start_time=time.time()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    read_tasks=[executor.submit(make_read_request) for _ in range(num_requests)]\n",
    "    concurrent.futures.wait(read_tasks)\n",
    "\n",
    "print(f\"Total time taken: {time.time() - total_start_time} secs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(read_times, 100, (0,1))\n",
    "plt.xlabel(\"Time taken for read (sec)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"A3: Time distribution for read execution\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
