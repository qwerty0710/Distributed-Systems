{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_url = \"http://localhost:5000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-1. Default configuration with 6 servers, 4 shards, 3 replicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"N\": 6,\n",
    "    \"schema\": {\n",
    "        \"columns\": [\"Stud_id\", \"Stud_name\", \"Stud_marks\"],\n",
    "        \"dtypes\": [\"Number\", \"String\", \"Number\"],\n",
    "    },\n",
    "    \"shards\": [\n",
    "        {\"Stud_id_low\": 0, \"Shard_id\": \"sh1\", \"Shard_size\": 4096},\n",
    "        {\"Stud_id_low\": 4096, \"Shard_id\": \"sh2\", \"Shard_size\": 4096},\n",
    "        {\"Stud_id_low\": 8192, \"Shard_id\": \"sh3\", \"Shard_size\": 4096},\n",
    "        {\"Stud_id_low\": 12288, \"Shard_id\": \"sh4\", \"Shard_size\": 4096},\n",
    "    ],\n",
    "    \"servers\": {\n",
    "        \"Server0\": [\"sh1\", \"sh2\"],\n",
    "        \"Server1\": [\"sh3\", \"sh4\"],\n",
    "        \"Server2\": [\"sh1\", \"sh3\"],\n",
    "        \"Server3\": [\"sh4\", \"sh2\"],\n",
    "        \"Server4\": [\"sh1\", \"sh4\"],\n",
    "        \"Server5\": [\"sh3\", \"sh2\"],\n",
    "    },\n",
    "}\n",
    "res = requests.post(f\"{docker_url}/init\", json=payload)\n",
    "print(res.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_requests = 10000\n",
    "\n",
    "write_times= []\n",
    "max_stud_id = 16383\n",
    "\n",
    "def make_write_request():\n",
    "    payload = {\n",
    "        \"data\": [\n",
    "            {\n",
    "                \"Stud_id\": random.randint(0, max_stud_id),\n",
    "                \"Stud_name\": \"GHI\",\n",
    "                \"Stud_marks\": random.randint(0, 100),\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "    start_time = time.time()\n",
    "    res = requests.post(f\"{docker_url}/write\", json=payload)\n",
    "    write_times.append(time.time() - start_time)\n",
    "    if res.status_code != 200:\n",
    "        print(f\"Error {res.status_code} in write\")\n",
    "\n",
    "total_start_time=time.time()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    write_tasks=[executor.submit(make_write_request) for _ in range(num_requests)]\n",
    "    concurrent.futures.wait(write_tasks)\n",
    "\n",
    "print(f\"Total time taken: {time.time() - total_start_time} secs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(write_times, 100, (0,4))\n",
    "plt.xlabel(\"Time taken for write (sec)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"A1: Time distribution for write execution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_requests = 10000\n",
    "\n",
    "read_times = []\n",
    "max_stud_id = 16383\n",
    "\n",
    "\n",
    "def make_read_request():\n",
    "    low = random.randint(0, max_stud_id)\n",
    "    payload = {\"Stud_id\": {\"low\": low, \"high\": low + 50}}\n",
    "    start_time = time.time()\n",
    "    res = requests.get(f\"{docker_url}/read\", json=payload)\n",
    "    read_times.append(time.time() - start_time)\n",
    "    if res.status_code != 200:\n",
    "        print(f\"Error {res.status_code} in read\")\n",
    "\n",
    "total_start_time=time.time()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    read_tasks=[executor.submit(make_read_request) for _ in range(num_requests)]\n",
    "    concurrent.futures.wait(read_tasks)\n",
    "\n",
    "print(f\"Total time taken: {time.time() - total_start_time} secs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(read_times, 100, (0,1))\n",
    "plt.xlabel(\"Time taken for read (sec)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"A1: Time distribution for read execution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"n\": 6,\n",
    "    \"servers\": [\"Server0\", \"Server1\", \"Server2\", \"Server3\", \"Server4\", \"Server5\"],\n",
    "}\n",
    "res = requests.delete(f\"{docker_url}/rm\", json=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-2. 6 servers, 4 shards, 6 replicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"N\": 6,\n",
    "    \"schema\": {\n",
    "        \"columns\": [\"Stud_id\", \"Stud_name\", \"Stud_marks\"],\n",
    "        \"dtypes\": [\"Number\", \"String\", \"Number\"],\n",
    "    },\n",
    "    \"shards\": [\n",
    "        {\"Stud_id_low\": 0, \"Shard_id\": \"sh1\", \"Shard_size\": 4096},\n",
    "        {\"Stud_id_low\": 4096, \"Shard_id\": \"sh2\", \"Shard_size\": 4096},\n",
    "        {\"Stud_id_low\": 8192, \"Shard_id\": \"sh3\", \"Shard_size\": 4096},\n",
    "        {\"Stud_id_low\": 12288, \"Shard_id\": \"sh4\", \"Shard_size\": 4096},\n",
    "    ],\n",
    "    \"servers\": {\n",
    "        \"Server0\": [\"sh1\", \"sh2\", \"sh3\", \"sh4\"],\n",
    "        \"Server1\": [\"sh1\", \"sh2\", \"sh3\", \"sh4\"],\n",
    "        \"Server2\": [\"sh1\", \"sh2\", \"sh3\", \"sh4\"],\n",
    "        \"Server3\": [\"sh1\", \"sh2\", \"sh3\", \"sh4\"],\n",
    "        \"Server4\": [\"sh1\", \"sh2\", \"sh3\", \"sh4\"],\n",
    "        \"Server5\": [\"sh1\", \"sh2\", \"sh3\", \"sh4\"],\n",
    "    },\n",
    "}\n",
    "res = requests.post(f\"{docker_url}/init\", json=payload)\n",
    "print(res.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_requests = 10000\n",
    "\n",
    "write_times= []\n",
    "max_stud_id = 16383\n",
    "\n",
    "def make_write_request():\n",
    "    payload = {\n",
    "        \"data\": [\n",
    "            {\n",
    "                \"Stud_id\": random.randint(0, max_stud_id),\n",
    "                \"Stud_name\": \"GHI\",\n",
    "                \"Stud_marks\": random.randint(0, 100),\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "    start_time = time.time()\n",
    "    res = requests.post(f\"{docker_url}/write\", json=payload)\n",
    "    write_times.append(time.time() - start_time)\n",
    "    if res.status_code != 200:\n",
    "        print(f\"Error {res.status_code} in write\")\n",
    "\n",
    "total_start_time=time.time()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    write_tasks=[executor.submit(make_write_request) for _ in range(num_requests)]\n",
    "    concurrent.futures.wait(write_tasks)\n",
    "\n",
    "print(f\"Total time taken: {time.time() - total_start_time} secs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(write_times, 100, (0,4))\n",
    "plt.xlabel(\"Time taken for write (sec)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"A2: Time distribution for write execution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_requests = 10000\n",
    "\n",
    "read_times = []\n",
    "max_stud_id = 16383\n",
    "\n",
    "\n",
    "def make_read_request():\n",
    "    low = random.randint(0, max_stud_id)\n",
    "    payload = {\"Stud_id\": {\"low\": low, \"high\": low + 50}}\n",
    "    start_time = time.time()\n",
    "    res = requests.get(f\"{docker_url}/read\", json=payload)\n",
    "    read_times.append(time.time() - start_time)\n",
    "    if res.status_code != 200:\n",
    "        print(f\"Error {res.status_code} in read\")\n",
    "\n",
    "total_start_time=time.time()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    read_tasks=[executor.submit(make_read_request) for _ in range(num_requests)]\n",
    "    concurrent.futures.wait(read_tasks)\n",
    "\n",
    "print(f\"Total time taken: {time.time() - total_start_time} secs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(read_times, 100, (0,1))\n",
    "plt.xlabel(\"Time taken for read (sec)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"A2: Time distribution for read execution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"n\": 6,\n",
    "    \"servers\": [\"Server0\", \"Server1\", \"Server2\", \"Server3\", \"Server4\", \"Server5\"],\n",
    "}\n",
    "res = requests.delete(f\"{docker_url}/rm\", json=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-3. 10 servers, 6 shards, 8 replicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"N\": 10,\n",
    "    \"schema\": {\n",
    "        \"columns\": [\"Stud_id\", \"Stud_name\", \"Stud_marks\"],\n",
    "        \"dtypes\": [\"Number\", \"String\", \"Number\"],\n",
    "    },\n",
    "    \"shards\": [\n",
    "        {\"Stud_id_low\": 0, \"Shard_id\": \"sh1\", \"Shard_size\": 4096},\n",
    "        {\"Stud_id_low\": 4096, \"Shard_id\": \"sh2\", \"Shard_size\": 4096},\n",
    "        {\"Stud_id_low\": 8192, \"Shard_id\": \"sh3\", \"Shard_size\": 4096},\n",
    "        {\"Stud_id_low\": 12288, \"Shard_id\": \"sh4\", \"Shard_size\": 4096},\n",
    "        {\"Stud_id_low\": 16384, \"Shard_id\": \"sh5\", \"Shard_size\": 4096},\n",
    "        {\"Stud_id_low\": 20480, \"Shard_id\": \"sh6\", \"Shard_size\": 4096},\n",
    "    ],\n",
    "    \"servers\": {\n",
    "        \"Server0\": [\"sh1\", \"sh2\", \"sh4\", \"sh6\"],\n",
    "        \"Server1\": [\"sh1\", \"sh2\", \"sh3\", \"sh4\", \"sh5\"],\n",
    "        \"Server2\": [\"sh1\", \"sh2\", \"sh3\", \"sh5\", \"sh6\"],\n",
    "        \"Server3\": [\"sh4\", \"sh2\", \"sh3\", \"sh5\", \"sh6\"],\n",
    "        \"Server4\": [\"sh1\", \"sh4\", \"sh5\", \"sh6\"],\n",
    "        \"Server5\": [\"sh3\", \"sh2\", \"sh5\", \"sh6\"],\n",
    "        \"Server6\": [\"sh1\", \"sh3\", \"sh4\", \"sh5\", \"sh6\"],\n",
    "        \"Server7\": [\"sh1\", \"sh3\", \"sh4\", \"sh2\", \"sh5\"],\n",
    "        \"Server8\": [\"sh1\", \"sh2\", \"sh3\", \"sh4\", \"sh6\"],\n",
    "        \"Server9\": [\"sh1\", \"sh2\", \"sh3\", \"sh4\", \"sh5\", \"sh6\"],\n",
    "    },\n",
    "}\n",
    "res = requests.post(f\"{docker_url}/init\", json=payload)\n",
    "print(res.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_requests = 10000\n",
    "\n",
    "write_times= []\n",
    "max_stud_id = 24575\n",
    "\n",
    "def make_write_request():\n",
    "    payload = {\n",
    "        \"data\": [\n",
    "            {\n",
    "                \"Stud_id\": random.randint(0, max_stud_id),\n",
    "                \"Stud_name\": \"GHI\",\n",
    "                \"Stud_marks\": random.randint(0, 100),\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "    start_time = time.time()\n",
    "    res = requests.post(f\"{docker_url}/write\", json=payload)\n",
    "    write_times.append(time.time() - start_time)\n",
    "    if res.status_code != 200:\n",
    "        print(f\"Error {res.status_code} in write\")\n",
    "\n",
    "total_start_time=time.time()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    write_tasks=[executor.submit(make_write_request) for _ in range(num_requests)]\n",
    "    concurrent.futures.wait(write_tasks)\n",
    "\n",
    "print(f\"Total time taken: {time.time() - total_start_time} secs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(write_times, 100, (0,4))\n",
    "plt.xlabel(\"Time taken for write (sec)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"A3: Time distribution for write execution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_requests = 10000\n",
    "\n",
    "read_times = []\n",
    "max_stud_id = 24575\n",
    "\n",
    "\n",
    "def make_read_request():\n",
    "    low = random.randint(0, max_stud_id)\n",
    "    payload = {\"Stud_id\": {\"low\": low, \"high\": low + 50}}\n",
    "    start_time = time.time()\n",
    "    res = requests.get(f\"{docker_url}/read\", json=payload)\n",
    "    read_times.append(time.time() - start_time)\n",
    "    if res.status_code != 200:\n",
    "        print(f\"Error {res.status_code} in read\")\n",
    "\n",
    "total_start_time=time.time()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    read_tasks=[executor.submit(make_read_request) for _ in range(num_requests)]\n",
    "    concurrent.futures.wait(read_tasks)\n",
    "\n",
    "print(f\"Total time taken: {time.time() - total_start_time} secs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(read_times, 100, (0,1))\n",
    "plt.xlabel(\"Time taken for read (sec)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"A3: Time distribution for read execution\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
